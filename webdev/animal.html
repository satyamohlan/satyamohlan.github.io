<!DOCTYPE html>
<html>
        <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="theme-color" content="#000"/>
    <head>
        <title>Detect Faces Sample</title>
       
        <link href="https://fonts.googleapis.com/css?family=Roboto&display=swap" rel="stylesheet">
        <style>
                 body {
  font: 12px/1.5 'Roboto', serif;

}
#canva{
    width:100%;
    display: none;
    
}
    .tags {
  background: #eee;
  border-radius: 3px;
  border:none;
  color: #322d2d;
    text-transform: capitalize;
    font-size: 15px;
  display: inline-block;
  height: 26px;
  line-height: 26px;
  padding: 0 20px 0 23px;
  position: relative;
  margin: 0 10px 10px 0;
  text-decoration: none;
  -webkit-transition: color 0.2s;
}

video{
    width: 100%;
}
#src{
    width:100%;
}
.tags:hover{
color:white;
background:black;
}
.tags:hover {
  background-color: crimson;
  color: white;
  cursor: pointer;
}

.tags:hover::after {
   border-left-color: crimson; 
}    
#support{
    text-decoration: none;
    text-align: center;
    width: 200px;
    margin-top:20px;
	background:none;
	font-weight: 400;
	font-size:17px;
	border:3px rgb(0, 0, 0) solid;
	border-radius: 10px;
	padding: 10px;
	transition: 0.5s;
	font-family: consolas,sans-serif;
}
#support:HOVER{
	BACKGROUND:rgb(0, 0, 0);
    color: rgb(255, 255, 255);
    cursor: pointer;
}

    
        
        </style>
    </head>
    <body>
        
    
            <div class="playerer">
<center>
<video id="player" autoplay></video></center>
<canvas id="canva" width=320 height=240 ></canvas>
<img src="" alt="" id="src">
</div>

<div class="info">

        <h1 style='text-align: center; margin-right:20px'>Computer vision Prototype<br><button onclick="processImage()" id='support'>Analyze Image</button></h1>
        <textarea id="responseTextArea" class="UIInput"
        style="width:90vw; height:400px;margin:0 5vw"></textarea>       
                  

    </div>
    <div id="tags">
    </div>
</div>
</div>
    </body>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.0/jquery.min.js"></script>
<script>
const player = document.getElementById('player');
const canvas = document.getElementById('canva');
const context = canvas.getContext('2d');
const captureButton = document.getElementById('capture');
const imga=document.getElementById('src');
var x;
var y;
var byteArr;
const constraints = {
  video: true,
  video:{facingMode: 'environment'}
};



navigator.mediaDevices.getUserMedia(constraints)
  .then((stream) => {
    // Attach the video stream to the video element and autoplay.
    if(window.innerHeight > window.innerWidth){
    canvas.height=stream.getTracks()[0].getSettings().width;
    canvas.width=stream.getTracks()[0].getSettings().height;}
    else if(window.innerHeight < window.innerWidth){
        canvas.width=stream.getTracks()[0].getSettings().width;
    canvas.height=stream.getTracks()[0].getSettings().height;}
    
    player.srcObject = stream;
  
  });
function processImage(stream) {
    $("#responseTextArea").val('');
    player.style.display='none';
    canvas.style.display='block';
    context.drawImage(player, 0, 0, canvas.width, canvas.height);
  //x=context.getImageData(0,0,canvas.width,canvas.height);
  x=tobin(canvas.toDataURL());

    // Replace <Subscription Key> with your valid subscription key.
    var subscriptionKey = "f37c1f0887504622b4e69bff84e0e730";

    var uriBase =
        "https://aiforearth.azure-api.net/species-recognition/v0.1/predict";

    // Request parameters.
    var params = {
            // Request parameters
            "topK": "1",
            "predictMode": "classifyAndDetect",
        };

    // Display the image.


    // Perform the REST API call.
    $.ajax({
        url: uriBase + "?" + $.param(params),

        // Request headers.
        beforeSend: function(xhrObj){
            xhrObj.setRequestHeader("Content-Type","application/octet-stream");
            xhrObj.setRequestHeader("Ocp-Apim-Subscription-Key", subscriptionKey);
        },

        type: "POST",

        // Request body.
        data:x,
        processData:false
    })

    .done(function(data) {
        // Show formatted JSON on webpage.
        $("#responseTextArea").val(JSON.stringify(data, null, 2));
        console.log(data);
    


    })

    .fail(function(jqXHR, textStatus, errorThrown) {
        // Display error message.
        var errorString = (errorThrown === "") ?
            "Error. " : errorThrown + " (" + jqXHR.status + "): ";
        errorString += (jqXHR.responseText === "") ?
            "" : (jQuery.parseJSON(jqXHR.responseText).message) ?
                jQuery.parseJSON(jqXHR.responseText).message :
                    jQuery.parseJSON(jqXHR.responseText).error.message;
        alert(errorString);
    });
};

function tobin(x){
var dataUri =x;
var data = dataUri.split(',')[1];
var mimeType = dataUri.split(';')[0].slice(5)

var bytes = window.atob(data);
var buf = new ArrayBuffer(bytes.length);
var byteArr = new Uint8Array(buf);

for (var i = 0; i < bytes.length; i++) {
    byteArr[i] = bytes.charCodeAt(i);
}

return byteArr;
}
function RandomColor() {
  var letters = '0123456789ABCDEF';
  var color = '#';
  for (var i = 0; i < 6; i++) {
    color += letters[Math.floor(Math.random() * 16)];
  }
  return color;
}


</script>

</html>